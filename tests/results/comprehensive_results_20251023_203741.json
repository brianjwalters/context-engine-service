{
  "metadata": {
    "execution_time": "2025-10-23T20:37:15.009542",
    "test_runner_version": "1.0.0",
    "project": "context-engine-service",
    "environment": "e2e"
  },
  "service_health": {
    "error": "'ServiceHealthChecker' object has no attribute 'check_all_services'"
  },
  "test_results": {
    "exit_code": 0,
    "duration_seconds": 26.80024003982544,
    "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.12.3, pytest-8.4.2, pluggy-1.6.0 -- /srv/luris/be/context-engine-service/venv/bin/python3\ncachedir: .pytest_cache\nrootdir: /srv/luris/be/context-engine-service\nconfigfile: pyproject.toml\nplugins: anyio-4.11.0, asyncio-1.2.0, cov-7.0.0\nasyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ncollecting ... collected 180 items / 75 deselected / 105 selected\n\ntests/fixtures/test_fixtures_validation.py::test_test_config_has_real_urls PASSED [  0%]\ntests/fixtures/test_fixtures_validation.py::test_performance_thresholds_are_lenient PASSED [  1%]\ntests/fixtures/test_fixtures_validation.py::test_fixture_implementation_summary PASSED [  2%]\ntests/unit/test_api_routes.py::TestCacheRoutes::test_get_cache_stats_success PASSED [  3%]\ntests/unit/test_api_routes.py::TestCacheRoutes::test_cache_stats_reset PASSED [  4%]\ntests/unit/test_api_routes.py::TestCacheRoutes::test_invalidate_cache_specific_case PASSED [  5%]\ntests/unit/test_api_routes.py::TestCacheRoutes::test_cache_warmup_batch PASSED [  6%]\ntests/unit/test_api_routes.py::TestCacheRoutes::test_get_cache_config PASSED [  7%]\ntests/unit/test_api_routes.py::TestCacheRoutes::test_cache_health_check PASSED [  8%]\ntests/unit/test_api_routes.py::TestHealthRoutes::test_root_endpoint PASSED [  9%]\ntests/unit/test_api_routes.py::TestHealthRoutes::test_health_endpoint PASSED [ 10%]\ntests/unit/test_api_routes.py::TestHealthRoutes::test_metrics_endpoint PASSED [ 11%]\ntests/unit/test_cache_manager.py::TestCacheEntry::test_cache_entry_creation PASSED [ 12%]\ntests/unit/test_cache_manager.py::TestCacheEntry::test_cache_entry_expiration PASSED [ 13%]\ntests/unit/test_cache_manager.py::TestCacheEntry::test_cache_entry_hit_tracking PASSED [ 14%]\ntests/unit/test_cache_manager.py::TestCacheEntry::test_cache_entry_no_expiration_when_future PASSED [ 15%]\ntests/unit/test_cache_manager.py::TestLRUCache::test_lru_cache_creation PASSED [ 16%]\ntests/unit/test_cache_manager.py::TestLRUCache::test_lru_cache_set_and_get PASSED [ 17%]\ntests/unit/test_cache_manager.py::TestLRUCache::test_lru_cache_get_nonexistent_key PASSED [ 18%]\ntests/unit/test_cache_manager.py::TestLRUCache::test_lru_cache_ttl_expiration PASSED [ 19%]\ntests/unit/test_cache_manager.py::TestLRUCache::test_lru_cache_eviction_policy PASSED [ 20%]\ntests/unit/test_cache_manager.py::TestLRUCache::test_lru_cache_move_to_end_on_get PASSED [ 20%]\ntests/unit/test_cache_manager.py::TestLRUCache::test_lru_cache_delete PASSED [ 21%]\ntests/unit/test_cache_manager.py::TestLRUCache::test_lru_cache_delete_nonexistent_key PASSED [ 22%]\ntests/unit/test_cache_manager.py::TestLRUCache::test_lru_cache_clear PASSED [ 23%]\ntests/unit/test_cache_manager.py::TestLRUCache::test_lru_cache_size PASSED [ 24%]\ntests/unit/test_cache_manager.py::TestLRUCache::test_lru_cache_get_stats PASSED [ 25%]\ntests/unit/test_cache_manager.py::TestCacheManager::test_cache_manager_creation SKIPPEDunt') [ 26%]\ntests/unit/test_cache_manager.py::TestCacheManager::test_cache_key_generation SKIPPEDunt') [ 27%]\ntests/unit/test_cache_manager.py::TestCacheManager::test_cache_key_hash_includes_params SKIPPEDunt') [ 28%]\ntests/unit/test_cache_manager.py::TestCacheManager::test_cache_set_and_get_memory SKIPPEDunt') [ 29%]\ntests/unit/test_cache_manager.py::TestCacheManager::test_cache_get_miss SKIPPEDunt') [ 30%]\ntests/unit/test_cache_manager.py::TestCacheManager::test_cache_delete SKIPPEDunt') [ 31%]\ntests/unit/test_cache_manager.py::TestCacheManager::test_cache_invalidate_case_all_scopes SKIPPEDunt') [ 32%]\ntests/unit/test_cache_manager.py::TestCacheManager::test_cache_ttl_based_on_case_status SKIPPEDunt') [ 33%]\ntests/unit/test_cache_manager.py::TestCacheManager::test_cache_stats SKIPPEDunt') [ 34%]\ntests/unit/test_cache_manager.py::TestCacheManager::test_cache_reset_stats SKIPPEDunt') [ 35%]\ntests/unit/test_cache_manager.py::TestCacheManager::test_create_cache_manager_factory SKIPPEDunt') [ 36%]\ntests/unit/test_cache_manager.py::TestCacheManagerEdgeCases::test_cache_handles_empty_value SKIPPEDunt') [ 37%]\ntests/unit/test_cache_manager.py::TestCacheManagerEdgeCases::test_cache_handles_large_value SKIPPEDunt') [ 38%]\ntests/unit/test_cache_manager.py::TestCacheManagerEdgeCases::test_cache_delete_nonexistent SKIPPEDunt') [ 39%]\ntests/unit/test_cache_manager.py::TestCacheManagerEdgeCases::test_cache_invalidate_case_empty SKIPPEDunt') [ 40%]\ntests/unit/test_cache_manager.py::TestCacheManagerEdgeCases::test_cache_hit_rate_tracking SKIPPEDunt') [ 40%]\ntests/unit/test_cache_manager.py::TestCacheManagerEdgeCases::test_cache_ttl_expiration SKIPPEDunt') [ 41%]\ntests/unit/test_cache_manager.py::TestCacheManagerEdgeCases::test_cache_handles_none_value SKIPPEDunt') [ 42%]\ntests/unit/test_cache_manager.py::TestCacheManagerEdgeCases::test_cache_handles_complex_objects SKIPPEDunt') [ 43%]\ntests/unit/test_cache_manager.py::TestCacheManagerEdgeCases::test_cache_key_validation SKIPPEDunt') [ 44%]\ntests/unit/test_cache_manager.py::TestCacheManagerEdgeCases::test_cache_lru_eviction SKIPPEDunt') [ 45%]\ntests/unit/test_cache_manager.py::TestCacheManagerEdgeCases::test_cache_size_tracking SKIPPEDunt') [ 46%]\ntests/unit/test_context_builder.py::TestContextBuilderInit::test_init PASSED [ 47%]\ntests/unit/test_context_builder.py::TestContextBuilderInit::test_factory_function PASSED [ 48%]\ntests/unit/test_context_builder.py::TestScopeDetermination::test_minimal_scope PASSED [ 49%]\ntests/unit/test_context_builder.py::TestScopeDetermination::test_standard_scope PASSED [ 50%]\ntests/unit/test_context_builder.py::TestScopeDetermination::test_comprehensive_scope PASSED [ 51%]\ntests/unit/test_context_builder.py::TestScopeDetermination::test_explicit_dimensions PASSED [ 52%]\ntests/unit/test_context_builder.py::TestScopeDetermination::test_invalid_scope PASSED [ 53%]\ntests/unit/test_context_builder.py::TestScopeDetermination::test_invalid_dimension_name PASSED [ 54%]\ntests/unit/test_context_builder.py::TestBuildContext::test_build_minimal_context PASSED [ 55%]\ntests/unit/test_context_builder.py::TestBuildContext::test_build_standard_context PASSED [ 56%]\ntests/unit/test_context_builder.py::TestBuildContext::test_build_comprehensive_context SKIPPED [ 57%]\ntests/unit/test_context_builder.py::TestBuildContext::test_build_selective_dimensions PASSED [ 58%]\ntests/unit/test_context_builder.py::TestParallelExecution::test_dimensions_built_in_parallel PASSED [ 59%]\ntests/unit/test_context_builder.py::TestQualityScoring::test_score_dimension_who PASSED [ 60%]\ntests/unit/test_context_builder.py::TestQualityScoring::test_score_dimension_what PASSED [ 60%]\ntests/unit/test_context_builder.py::TestQualityScoring::test_score_dimension_where PASSED [ 61%]\ntests/unit/test_context_builder.py::TestQualityScoring::test_calculate_context_score PASSED [ 62%]\ntests/unit/test_context_builder.py::TestQualityScoring::test_calculate_context_score_with_failures PASSED [ 63%]\ntests/unit/test_context_builder.py::TestErrorHandling::test_graceful_degradation_on_analyzer_failure PASSED [ 64%]\ntests/unit/test_context_builder.py::TestDimensionQuality::test_get_dimension_quality PASSED [ 65%]\ntests/unit/test_context_builder.py::TestDimensionQuality::test_get_dimension_quality_invalid_dimension PASSED [ 66%]\ntests/unit/test_context_builder.py::TestDimensionRefresh::test_refresh_dimension PASSED [ 67%]\ntests/unit/test_context_builder.py::TestDimensionRefresh::test_refresh_dimension_invalid PASSED [ 68%]\ntests/unit/test_context_builder.py::TestHelperMethods::test_get_case_name PASSED [ 69%]\ntests/unit/test_context_builder.py::TestHelperMethods::test_get_case_name_fallback PASSED [ 70%]\ntests/unit/test_context_builder.py::TestHelperMethods::test_count_data_points_who PASSED [ 71%]\ntests/unit/test_context_builder.py::TestHelperMethods::test_count_data_points_none PASSED [ 72%]\ntests/unit/test_context_builder.py::TestCaseIsolation::test_case_isolation PASSED [ 73%]\ntests/unit/test_dimension_analyzer.py::TestWhoAnalyzer::test_who_analyzer_initialization PASSED [ 74%]\ntests/unit/test_dimension_analyzer.py::TestWhoAnalyzer::test_who_analyze_real_case PASSED [ 75%]\ntests/unit/test_dimension_analyzer.py::TestWhoAnalyzer::test_who_empty_case PASSED [ 76%]\ntests/unit/test_dimension_analyzer.py::TestWhatAnalyzer::test_what_analyzer_initialization PASSED [ 77%]\ntests/unit/test_dimension_analyzer.py::TestWhatAnalyzer::test_what_analyze_real_case PASSED [ 78%]\ntests/unit/test_dimension_analyzer.py::TestWhereAnalyzer::test_where_analyzer_initialization PASSED [ 79%]\ntests/unit/test_dimension_analyzer.py::TestWhereAnalyzer::test_where_analyze_real_case PASSED [ 80%]\ntests/unit/test_dimension_analyzer.py::TestWhenAnalyzer::test_when_analyzer_initialization PASSED [ 80%]\ntests/unit/test_dimension_analyzer.py::TestWhenAnalyzer::test_when_analyze_real_case PASSED [ 81%]\ntests/unit/test_dimension_analyzer.py::TestWhyAnalyzer::test_why_analyzer_initialization PASSED [ 82%]\ntests/unit/test_dimension_analyzer.py::TestWhyAnalyzer::test_why_analyze_real_case PASSED [ 83%]\ntests/unit/test_dimension_analyzer.py::TestDimensionAnalyzerIntegration::test_all_analyzers_real_case PASSED [ 84%]\ntests/unit/test_graphrag_client.py::TestResponseModels::test_graph_entity_validation PASSED [ 85%]\ntests/unit/test_graphrag_client.py::TestResponseModels::test_graph_entity_uppercase_type PASSED [ 86%]\ntests/unit/test_graphrag_client.py::TestResponseModels::test_graph_relationship_validation PASSED [ 87%]\ntests/unit/test_graphrag_client.py::TestResponseModels::test_graph_community_validation PASSED [ 88%]\ntests/unit/test_graphrag_client.py::TestClientInitialization::test_client_initialization PASSED [ 89%]\ntests/unit/test_graphrag_client.py::TestClientInitialization::test_client_custom_config PASSED [ 90%]\ntests/unit/test_graphrag_client.py::TestClientInitialization::test_factory_function PASSED [ 91%]\ntests/unit/test_graphrag_client.py::TestRealServiceIntegration::test_real_health_check PASSED [ 92%]\ntests/unit/test_graphrag_client.py::TestRealServiceIntegration::test_real_graph_stats PASSED [ 93%]\ntests/unit/test_graphrag_client.py::TestRealServiceIntegration::test_real_graph_stats_case_specific PASSED [ 94%]\ntests/unit/test_graphrag_client.py::TestRealServiceIntegration::test_real_case_query SKIPPED [ 95%]\ntests/unit/test_graphrag_client.py::TestRealServiceIntegration::test_real_legal_research SKIPPEDr url\n'http://10.10.0.87:8010/api/v1/graphrag/query'\nFor more information\ncheck: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404)     [ 96%]\ntests/unit/test_graphrag_client.py::TestRealServiceIntegration::test_case_id_validation PASSED [ 97%]\ntests/unit/test_graphrag_client.py::TestRealServiceIntegration::test_get_case_entities_validation PASSED [ 98%]\ntests/unit/test_graphrag_client.py::TestContextManager::test_context_manager_usage PASSED [ 99%]\ntests/unit/test_graphrag_client.py::TestContextManager::test_manual_close PASSED [100%]\n\n=============================== warnings summary ===============================\nsrc/models/dimensions.py:43\n  /srv/luris/be/context-engine-service/src/models/dimensions.py:43: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator('role')\n\nsrc/models/dimensions.py:157\n  /srv/luris/be/context-engine-service/src/models/dimensions.py:157: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator('confidence')\n\nsrc/models/dimensions.py:498\n  /srv/luris/be/context-engine-service/src/models/dimensions.py:498: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    @validator('is_sufficient', always=True)\n\nsrc/api/routes/context.py:54\n  /srv/luris/be/context-engine-service/src/api/routes/context.py:54: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    class ContextRetrievalRequest(BaseModel):\n\nsrc/api/routes/context.py:82\n  /srv/luris/be/context-engine-service/src/api/routes/context.py:82: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    class DimensionRequest(BaseModel):\n\nsrc/api/routes/context.py:416\n  /srv/luris/be/context-engine-service/src/api/routes/context.py:416: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    class BatchContextRequest(BaseModel):\n\nsrc/api/routes/cache.py:25\n  /srv/luris/be/context-engine-service/src/api/routes/cache.py:25: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    class CacheInvalidationRequest(BaseModel):\n\nsrc/api/routes/cache.py:276\n  /srv/luris/be/context-engine-service/src/api/routes/cache.py:276: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n    class CacheWarmupRequest(BaseModel):\n\ntests/unit/test_api_routes.py: 4 warnings\ntests/unit/test_context_builder.py: 24 warnings\ntests/unit/test_dimension_analyzer.py: 7 warnings\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/supabase/_sync/client.py:303: DeprecationWarning: The 'timeout' parameter is deprecated. Please configure it in the http client instead.\n    return SyncPostgrestClient(\n\ntests/unit/test_api_routes.py: 4 warnings\ntests/unit/test_context_builder.py: 24 warnings\ntests/unit/test_dimension_analyzer.py: 7 warnings\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/supabase/_sync/client.py:303: DeprecationWarning: The 'verify' parameter is deprecated. Please configure it in the http client instead.\n    return SyncPostgrestClient(\n\ntests/unit/test_api_routes.py: 15 warnings\ntests/unit/test_context_builder.py: 50 warnings\ntests/unit/test_dimension_analyzer.py: 19 warnings\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/postgrest/_sync/client.py:89: DeprecationWarning: The 'timeout' parameter is deprecated. Please configure it in the http client instead.\n    return SyncPostgrestClient(\n\ntests/unit/test_api_routes.py: 15 warnings\ntests/unit/test_context_builder.py: 50 warnings\ntests/unit/test_dimension_analyzer.py: 19 warnings\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/postgrest/_sync/client.py:89: DeprecationWarning: The 'verify' parameter is deprecated. Please configure it in the http client instead.\n    return SyncPostgrestClient(\n\ntests/unit/test_context_builder.py::TestContextBuilderInit::test_init\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_init' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestContextBuilderInit::test_factory_function\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_factory_function' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestScopeDetermination::test_minimal_scope\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_minimal_scope' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestScopeDetermination::test_standard_scope\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_standard_scope' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestScopeDetermination::test_comprehensive_scope\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_comprehensive_scope' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestScopeDetermination::test_explicit_dimensions\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_explicit_dimensions' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestScopeDetermination::test_invalid_scope\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_invalid_scope' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestScopeDetermination::test_invalid_dimension_name\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_invalid_dimension_name' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestBuildContext::test_build_minimal_context\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_minimal_context' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestBuildContext::test_build_minimal_context\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_build_minimal_context' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestBuildContext::test_build_standard_context\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_standard_context' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestBuildContext::test_build_standard_context\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_build_standard_context' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestBuildContext::test_build_comprehensive_context\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_comprehensive_context' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestBuildContext::test_build_comprehensive_context\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_build_comprehensive_context' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestBuildContext::test_build_selective_dimensions\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_build_selective_dimensions' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestBuildContext::test_build_selective_dimensions\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_build_selective_dimensions' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestParallelExecution::test_dimensions_built_in_parallel\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_dimensions_built_in_parallel' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestParallelExecution::test_dimensions_built_in_parallel\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_dimensions_built_in_parallel' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestQualityScoring::test_score_dimension_who\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_score_dimension_who' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestQualityScoring::test_score_dimension_what\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_score_dimension_what' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestQualityScoring::test_score_dimension_where\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_score_dimension_where' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestQualityScoring::test_calculate_context_score\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_calculate_context_score' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestQualityScoring::test_calculate_context_score_with_failures\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_calculate_context_score_with_failures' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestErrorHandling::test_graceful_degradation_on_analyzer_failure\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_graceful_degradation_on_analyzer_failure' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestErrorHandling::test_graceful_degradation_on_analyzer_failure\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_graceful_degradation_on_analyzer_failure' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestDimensionQuality::test_get_dimension_quality\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_dimension_quality' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestDimensionQuality::test_get_dimension_quality\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_get_dimension_quality' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestDimensionQuality::test_get_dimension_quality_invalid_dimension\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_dimension_quality_invalid_dimension' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestDimensionQuality::test_get_dimension_quality_invalid_dimension\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_get_dimension_quality_invalid_dimension' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestDimensionRefresh::test_refresh_dimension\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_refresh_dimension' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestDimensionRefresh::test_refresh_dimension\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_refresh_dimension' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestDimensionRefresh::test_refresh_dimension_invalid\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_refresh_dimension_invalid' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestDimensionRefresh::test_refresh_dimension_invalid\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_refresh_dimension_invalid' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestHelperMethods::test_get_case_name\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_case_name' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestHelperMethods::test_get_case_name_fallback\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_get_case_name_fallback' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestHelperMethods::test_count_data_points_who\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_count_data_points_who' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestHelperMethods::test_count_data_points_none\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_count_data_points_none' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestCaseIsolation::test_case_isolation\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_case_isolation' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_context_builder.py::TestCaseIsolation::test_case_isolation\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_case_isolation' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhoAnalyzer::test_who_analyzer_initialization\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_who_analyzer_initialization' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhoAnalyzer::test_who_analyzer_initialization\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_who_analyzer_initialization' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhoAnalyzer::test_who_analyze_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_who_analyze_real_case' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhoAnalyzer::test_who_analyze_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_who_analyze_real_case' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhoAnalyzer::test_who_empty_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_who_empty_case' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhoAnalyzer::test_who_empty_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_who_empty_case' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhatAnalyzer::test_what_analyzer_initialization\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_what_analyzer_initialization' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhatAnalyzer::test_what_analyzer_initialization\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_what_analyzer_initialization' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhatAnalyzer::test_what_analyze_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_what_analyze_real_case' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhatAnalyzer::test_what_analyze_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_what_analyze_real_case' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhereAnalyzer::test_where_analyzer_initialization\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_where_analyzer_initialization' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhereAnalyzer::test_where_analyzer_initialization\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_where_analyzer_initialization' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhereAnalyzer::test_where_analyze_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_where_analyze_real_case' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhereAnalyzer::test_where_analyze_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_where_analyze_real_case' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhenAnalyzer::test_when_analyzer_initialization\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_when_analyzer_initialization' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhenAnalyzer::test_when_analyzer_initialization\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_when_analyzer_initialization' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhenAnalyzer::test_when_analyze_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_when_analyze_real_case' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhenAnalyzer::test_when_analyze_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_when_analyze_real_case' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhyAnalyzer::test_why_analyzer_initialization\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_why_analyzer_initialization' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhyAnalyzer::test_why_analyzer_initialization\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_why_analyzer_initialization' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhyAnalyzer::test_why_analyze_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_why_analyze_real_case' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestWhyAnalyzer::test_why_analyze_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_why_analyze_real_case' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestDimensionAnalyzerIntegration::test_all_analyzers_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/fixtures.py:1182: PytestRemovedIn9Warning: 'test_all_analyzers_real_case' requested an async fixture 'graphrag_client', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.\n  See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture\n    warnings.warn(\n\ntests/unit/test_dimension_analyzer.py::TestDimensionAnalyzerIntegration::test_all_analyzers_real_case\n  /srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/pytest_asyncio/plugin.py:678: PytestDeprecationWarning: asyncio test 'test_all_analyzers_real_case' requested async @pytest.fixture 'graphrag_client' in strict mode. You might want to use @pytest_asyncio.fixture or switch to auto mode. This will become an error in future versions of pytest-asyncio.\n    warnings.warn(\n\n-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n- generated xml file: /srv/luris/be/context-engine-service/tests/results/junit_report.xml -\n================================ tests coverage ================================\n_______________ coverage: platform linux, python 3.12.3-final-0 ________________\n\nName                             Stmts   Miss  Cover   Missing\n--------------------------------------------------------------\nsrc/__init__.py                      0      0   100%\nsrc/api/__init__.py                  0      0   100%\nsrc/api/main.py                     29      0   100%\nsrc/api/routes/__init__.py           0      0   100%\nsrc/api/routes/cache.py            108     31    71%   101-103, 145-147, 218-220, 248-269, 346-349, 360-362, 433-435, 500-502\nsrc/api/routes/context.py          122     62    49%   197-202, 230-236, 267-306, 336-356, 383-409, 467-507\nsrc/clients/__init__.py              0      0   100%\nsrc/clients/graphrag_client.py     231     84    64%   248-251, 259-269, 368, 376-393, 432-453, 487-513, 548-568, 632-672, 736, 747-758, 792-813, 847-870, 952-954, 992-1012\nsrc/clients/supabase_client.py     887    552    38%   34, 36, 55-88, 157, 159, 161, 264-270, 285-289, 306-312, 324-332, 337-352, 361-378, 382-384, 397-403, 406-412, 415-420, 433, 437, 450, 479-490, 496-509, 517-528, 535-549, 553-562, 566-585, 589-598, 632-677, 684-735, 739-741, 745-748, 753, 757, 761-762, 766, 795-820, 840, 869-873, 950, 961-979, 985, 996-1004, 1011, 1019-1020, 1032, 1079-1088, 1095, 1100, 1104-1110, 1114-1128, 1136, 1146-1156, 1161-1170, 1209-1226, 1232-1236, 1315-1317, 1374, 1421, 1431, 1441, 1454, 1497-1498, 1502-1503, 1507-1508, 1512-1513, 1517-1518, 1522-1523, 1527-1528, 1541-1542, 1551-1552, 1556-1557, 1561-1562, 1580-1581, 1585-1586, 1590-1591, 1601-1602, 1606-1607, 1639, 1652, 1654, 1656, 1658, 1660, 1662, 1664, 1666, 1669-1675, 1682-1683, 1685, 1687, 1689-1690, 1692, 1700-1704, 1726-1731, 1735-1736, 1740-1755, 1774-1779, 1783-1784, 1788-1789, 1793-1794, 1798-1799, 1803-1804, 1808-1809, 1813-1847, 1865-1869, 1873-1874, 1878-1879, 1883-1884, 1888-1889, 1893-1923, 1943-1949, 1953-1954, 1958-1959, 1963-1986, 2016-2024, 2050-2056, 2073-2075, 2101-2109, 2132-2134, 2149-2150, 2172-2175, 2192-2206, 2210-2254, 2258-2261, 2265-2279, 2283-2292, 2296-2304, 2355\nsrc/core/__init__.py                 0      0   100%\nsrc/core/cache_manager.py          194     55    72%   330, 369-371, 376-384, 388-398, 428-444, 474-486, 494, 497-498, 501-502, 526-527, 585, 590, 595, 604, 615, 620\nsrc/core/context_builder.py        175     28    84%   162-164, 217, 310-315, 338, 379, 431, 482, 484-486, 509-525, 603-625\nsrc/core/dimension_analyzer.py     315     96    70%   78, 97-102, 180-183, 205, 219, 235-245, 259-268, 282-292, 306-316, 337-342, 353-354, 367-368, 439-441, 458, 471-480, 487-491, 498-502, 513-522, 533-542, 552, 554, 578-579, 637-639, 656, 734-736, 752, 772-784, 844-846, 861, 878-887, 899-906, 917-918\nsrc/models/__init__.py               0      0   100%\nsrc/models/dimensions.py           207     23    89%   48, 129, 133, 160, 201, 205, 244, 310-313, 317-319, 387, 391-394, 434-441, 445, 503\nsrc/utils/__init__.py                0      0   100%\n--------------------------------------------------------------\nTOTAL                             2268    931    59%\nCoverage HTML written to dir /srv/luris/be/context-engine-service/tests/results/coverage_html\nCoverage JSON written to file /srv/luris/be/context-engine-service/tests/results/coverage.json\n========= 80 passed, 25 skipped, 75 deselected, 309 warnings in 24.87s =========\n",
    "stderr": "2025-10-23 20:37:16,454 - root - INFO - ======================================================================\n2025-10-23 20:37:16,454 - root - INFO - Context Engine Service - Test Session Starting\n2025-10-23 20:37:16,454 - root - INFO - ======================================================================\n/srv/luris/be/context-engine-service/venv/lib/python3.12/site-packages/_pytest/unraisableexception.py:33: RuntimeWarning: coroutine 'SelectQueryBuilder.execute' was never awaited\n  gc.collect()\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
    "test_results": {
      "summary": {
        "total": 105,
        "passed": 80,
        "failed": 0,
        "skipped": 25
      },
      "tests": []
    }
  },
  "performance_metrics": {},
  "dimension_samples": {
    "who": {
      "courts": [],
      "parties": [],
      "judges": [],
      "attorneys": []
    },
    "what": {
      "statutes": [],
      "case_citations": [],
      "legal_issues": [],
      "causes_of_action": []
    },
    "where": {
      "jurisdictions": [],
      "venues": [],
      "courts": []
    },
    "when": {
      "dates": [],
      "deadlines": [],
      "timeline_events": []
    },
    "why": {
      "precedents": [],
      "legal_theories": [],
      "arguments": [],
      "reasoning": []
    }
  },
  "coverage": {
    "percent_covered": 58.95,
    "num_statements": 2268,
    "covered_lines": 1337,
    "missing_lines": 931,
    "excluded_lines": 0,
    "coverage_html_path": "/srv/luris/be/context-engine-service/tests/results/coverage_html/index.html"
  },
  "summary": {
    "test_counts": {
      "total": 105,
      "passed": 80,
      "failed": 0,
      "skipped": 25,
      "pass_rate_percent": 76.19
    },
    "performance": {
      "avg_response_time_s": 0,
      "max_response_time_s": 0,
      "min_response_time_s": 0,
      "p50_s": 0,
      "p95_s": 0,
      "p99_s": 0,
      "endpoint_performance": {}
    },
    "duration": 26.8,
    "failed_tests": []
  }
}